{
    "results": [
        {
            "entry_id": "http://arxiv.org/abs/1705.10201v2",
            "updated": "2017-08-31 15:53:28+00:00",
            "published": "2017-05-29 14:07:33+00:00",
            "title": "Machine Learned Learning Machines",
            "authors": [
                "Leigh Sheneman",
                "Arend Hintze"
            ],
            "summary": "There are two common approaches for optimizing the performance of a machine:\ngenetic algorithms and machine learning. A genetic algorithm is applied over\nmany generations whereas machine learning works by applying feedback until the\nsystem meets a performance threshold. Though these are methods that typically\noperate separately, we combine evolutionary adaptation and machine learning\ninto one approach. Our focus is on machines that can learn during their\nlifetime, but instead of equipping them with a machine learning algorithm we\naim to let them evolve their ability to learn by themselves. We use evolvable\nnetworks of probabilistic and deterministic logic gates, known as Markov\nBrains, as our computational model organism. The ability of Markov Brains to\nlearn is augmented by a novel adaptive component that can change its\ncomputational behavior based on feedback. We show that Markov Brains can indeed\nevolve to incorporate these feedback gates to improve their adaptability to\nvariable environments. By combining these two methods, we now also implemented\na computational model that can be used to study the evolution of learning.",
            "comment": "",
            "journal_ref": "",
            "doi": "",
            "primary_category": "cs.AI",
            "categories": [
                "cs.AI"
            ],
            "links": [
                "http://arxiv.org/abs/1705.10201v2",
                "http://arxiv.org/pdf/1705.10201v2"
            ],
            "pdf_url": "http://arxiv.org/pdf/1705.10201v2"
        },
        {
            "entry_id": "http://arxiv.org/abs/2105.02569v3",
            "updated": "2024-02-11 10:21:20+00:00",
            "published": "2021-05-06 10:27:03+00:00",
            "title": "Machine Collaboration",
            "authors": [
                "Qingfeng Liu",
                "Yang Feng"
            ],
            "summary": "We propose a new ensemble framework for supervised learning, called machine\ncollaboration (MaC), using a collection of base machines for prediction tasks.\nUnlike bagging/stacking (a parallel & independent framework) and boosting (a\nsequential & top-down framework), MaC is a type of circular & interactive\nlearning framework. The circular & interactive feature helps the base machines\nto transfer information circularly and update their structures and parameters\naccordingly. The theoretical result on the risk bound of the estimator from MaC\nreveals that the circular & interactive feature can help MaC reduce risk via a\nparsimonious ensemble. We conduct extensive experiments on MaC using both\nsimulated data and 119 benchmark real datasets. The results demonstrate that in\nmost cases, MaC performs significantly better than several other\nstate-of-the-art methods, including classification and regression trees, neural\nnetworks, stacking, and boosting.",
            "comment": "",
            "journal_ref": "",
            "doi": "",
            "primary_category": "stat.ML",
            "categories": [
                "stat.ML",
                "cs.LG",
                "econ.EM",
                "68Q32, 68T05, 62G05, 68T07, 62J02, 62G08, 62J07, 62J12",
                "G.3; I.2.6; I.6.4; I.6.5"
            ],
            "links": [
                "http://arxiv.org/abs/2105.02569v3",
                "http://arxiv.org/pdf/2105.02569v3"
            ],
            "pdf_url": "http://arxiv.org/pdf/2105.02569v3"
        },
        {
            "entry_id": "http://arxiv.org/abs/1912.03817v3",
            "updated": "2020-12-15 05:39:28+00:00",
            "published": "2019-12-09 02:16:53+00:00",
            "title": "Machine Unlearning",
            "authors": [
                "Lucas Bourtoule",
                "Varun Chandrasekaran",
                "Christopher A. Choquette-Choo",
                "Hengrui Jia",
                "Adelin Travers",
                "Baiwu Zhang",
                "David Lie",
                "Nicolas Papernot"
            ],
            "summary": "Once users have shared their data online, it is generally difficult for them\nto revoke access and ask for the data to be deleted. Machine learning (ML)\nexacerbates this problem because any model trained with said data may have\nmemorized it, putting users at risk of a successful privacy attack exposing\ntheir information. Yet, having models unlearn is notoriously difficult. We\nintroduce SISA training, a framework that expedites the unlearning process by\nstrategically limiting the influence of a data point in the training procedure.\nWhile our framework is applicable to any learning algorithm, it is designed to\nachieve the largest improvements for stateful algorithms like stochastic\ngradient descent for deep neural networks. SISA training reduces the\ncomputational overhead associated with unlearning, even in the worst-case\nsetting where unlearning requests are made uniformly across the training set.\nIn some cases, the service provider may have a prior on the distribution of\nunlearning requests that will be issued by users. We may take this prior into\naccount to partition and order data accordingly, and further decrease overhead\nfrom unlearning. Our evaluation spans several datasets from different domains,\nwith corresponding motivations for unlearning. Under no distributional\nassumptions, for simple learning tasks, we observe that SISA training improves\ntime to unlearn points from the Purchase dataset by 4.63x, and 2.45x for the\nSVHN dataset, over retraining from scratch. SISA training also provides a\nspeed-up of 1.36x in retraining for complex learning tasks such as ImageNet\nclassification; aided by transfer learning, this results in a small degradation\nin accuracy. Our work contributes to practical data governance in machine\nunlearning.",
            "comment": "Published in IEEE S&P 2021",
            "journal_ref": "",
            "doi": "",
            "primary_category": "cs.CR",
            "categories": [
                "cs.CR",
                "cs.AI",
                "cs.LG"
            ],
            "links": [
                "http://arxiv.org/abs/1912.03817v3",
                "http://arxiv.org/pdf/1912.03817v3"
            ],
            "pdf_url": "http://arxiv.org/pdf/1912.03817v3"
        },
        {
            "entry_id": "http://arxiv.org/abs/1605.03795v3",
            "updated": "2017-12-08 08:17:58+00:00",
            "published": "2016-05-12 13:08:11+00:00",
            "title": "Exponential Machines",
            "authors": [
                "Alexander Novikov",
                "Mikhail Trofimov",
                "Ivan Oseledets"
            ],
            "summary": "Modeling interactions between features improves the performance of machine\nlearning solutions in many domains (e.g. recommender systems or sentiment\nanalysis). In this paper, we introduce Exponential Machines (ExM), a predictor\nthat models all interactions of every order. The key idea is to represent an\nexponentially large tensor of parameters in a factorized format called Tensor\nTrain (TT). The Tensor Train format regularizes the model and lets you control\nthe number of underlying parameters. To train the model, we develop a\nstochastic Riemannian optimization procedure, which allows us to fit tensors\nwith 2^160 entries. We show that the model achieves state-of-the-art\nperformance on synthetic data with high-order interactions and that it works on\npar with high-order factorization machines on a recommender system dataset\nMovieLens 100K.",
            "comment": "ICLR-2017 workshop track paper",
            "journal_ref": "",
            "doi": "",
            "primary_category": "stat.ML",
            "categories": [
                "stat.ML",
                "cs.LG"
            ],
            "links": [
                "http://arxiv.org/abs/1605.03795v3",
                "http://arxiv.org/pdf/1605.03795v3"
            ],
            "pdf_url": "http://arxiv.org/pdf/1605.03795v3"
        },
        {
            "entry_id": "http://arxiv.org/abs/2008.10522v2",
            "updated": "2023-06-09 08:27:03+00:00",
            "published": "2020-08-24 15:49:54+00:00",
            "title": "Machine Semiotics",
            "authors": [
                "Peter beim Graben",
                "Markus Huber-Liebl",
                "Peter Klimczak",
                "Günther Wirsching"
            ],
            "summary": "Recognizing a basic difference between the semiotics of humans and machines\npresents a possibility to overcome the shortcomings of current speech assistive\ndevices. For the machine, the meaning of a (human) utterance is defined by its\nown scope of actions. Machines, thus, do not need to understand the\nconventional meaning of an utterance. Rather, they draw conversational\nimplicatures in the sense of (neo-)Gricean pragmatics. For speech assistive\ndevices, the learning of machine-specific meanings of human utterances, i.e.\nthe fossilization of conversational implicatures into conventionalized ones by\ntrial and error through lexicalization appears to be sufficient. Using the\nquite trivial example of a cognitive heating device, we show that - based on\ndynamic semantics - this process can be formalized as the reinforcement\nlearning of utterance-meaning pairs (UMP).",
            "comment": "48 pages, 4 tables",
            "journal_ref": "",
            "doi": "",
            "primary_category": "cs.CL",
            "categories": [
                "cs.CL",
                "cs.AI"
            ],
            "links": [
                "http://arxiv.org/abs/2008.10522v2",
                "http://arxiv.org/pdf/2008.10522v2"
            ],
            "pdf_url": "http://arxiv.org/pdf/2008.10522v2"
        },
        {
            "entry_id": "http://arxiv.org/abs/2311.11388v2",
            "updated": "2023-11-22 08:15:13+00:00",
            "published": "2023-11-19 18:12:21+00:00",
            "title": "Machine Culture",
            "authors": [
                "Levin Brinkmann",
                "Fabian Baumann",
                "Jean-François Bonnefon",
                "Maxime Derex",
                "Thomas F. Müller",
                "Anne-Marie Nussberger",
                "Agnieszka Czaplicka",
                "Alberto Acerbi",
                "Thomas L. Griffiths",
                "Joseph Henrich",
                "Joel Z. Leibo",
                "Richard McElreath",
                "Pierre-Yves Oudeyer",
                "Jonathan Stray",
                "Iyad Rahwan"
            ],
            "summary": "The ability of humans to create and disseminate culture is often credited as\nthe single most important factor of our success as a species. In this\nPerspective, we explore the notion of machine culture, culture mediated or\ngenerated by machines. We argue that intelligent machines simultaneously\ntransform the cultural evolutionary processes of variation, transmission, and\nselection. Recommender algorithms are altering social learning dynamics.\nChatbots are forming a new mode of cultural transmission, serving as cultural\nmodels. Furthermore, intelligent machines are evolving as contributors in\ngenerating cultural traits--from game strategies and visual art to scientific\nresults. We provide a conceptual framework for studying the present and\nanticipated future impact of machines on cultural evolution, and present a\nresearch agenda for the study of machine culture.",
            "comment": "",
            "journal_ref": "Nat Hum Behav 7, 1855-1868 (2023)",
            "doi": "10.1038/s41562-023-01742-2",
            "primary_category": "cs.CY",
            "categories": [
                "cs.CY"
            ],
            "links": [
                "http://dx.doi.org/10.1038/s41562-023-01742-2",
                "http://arxiv.org/abs/2311.11388v2",
                "http://arxiv.org/pdf/2311.11388v2"
            ],
            "pdf_url": "http://arxiv.org/pdf/2311.11388v2"
        },
        {
            "entry_id": "http://arxiv.org/abs/2302.09248v2",
            "updated": "2023-02-22 18:17:32+00:00",
            "published": "2023-02-18 06:48:23+00:00",
            "title": "Machine Love",
            "authors": [
                "Joel Lehman"
            ],
            "summary": "While ML generates much economic value, many of us have problematic\nrelationships with social media and other ML-powered applications. One reason\nis that ML often optimizes for what we want in the moment, which is easy to\nquantify but at odds with what is known scientifically about human flourishing.\nThus, through its impoverished models of us, ML currently falls far short of\nits exciting potential, which is for it to help us to reach ours. While there\nis no consensus on defining human flourishing, from diverse perspectives across\npsychology, philosophy, and spiritual traditions, love is understood to be one\nof its primary catalysts. Motivated by this view, this paper explores whether\nthere is a useful conception of love fitting for machines to embody, as\nhistorically it has been generative to explore whether a nebulous concept, such\nas life or intelligence, can be thoughtfully abstracted and reimagined, as in\nthe fields of machine intelligence or artificial life. This paper forwards a\ncandidate conception of machine love, inspired in particular by work in\npositive psychology and psychotherapy: to provide unconditional support\nenabling humans to autonomously pursue their own growth and development.\nThrough proof of concept experiments, this paper aims to highlight the need for\nricher models of human flourishing in ML, provide an example framework through\nwhich positive psychology can be combined with ML to realize a rough conception\nof machine love, and demonstrate that current language models begin to enable\nembodying qualitative humanistic principles. The conclusion is that though at\npresent ML may often serve to addict, distract, or divide us, an alternative\npath may be opening up: We may align ML to support our growth, through it\nhelping us to align ourselves towards our highest aspirations.",
            "comment": "",
            "journal_ref": "",
            "doi": "",
            "primary_category": "cs.AI",
            "categories": [
                "cs.AI",
                "cs.CY",
                "cs.LG",
                "cs.NE"
            ],
            "links": [
                "http://arxiv.org/abs/2302.09248v2",
                "http://arxiv.org/pdf/2302.09248v2"
            ],
            "pdf_url": "http://arxiv.org/pdf/2302.09248v2"
        },
        {
            "entry_id": "http://arxiv.org/abs/1102.1808v3",
            "updated": "2011-02-11 05:10:57+00:00",
            "published": "2011-02-09 08:25:36+00:00",
            "title": "From Machine Learning to Machine Reasoning",
            "authors": [
                "Leon Bottou"
            ],
            "summary": "A plausible definition of \"reasoning\" could be \"algebraically manipulating\npreviously acquired knowledge in order to answer a new question\". This\ndefinition covers first-order logical inference or probabilistic inference. It\nalso includes much simpler manipulations commonly used to build large learning\nsystems. For instance, we can build an optical character recognition system by\nfirst training a character segmenter, an isolated character recognizer, and a\nlanguage model, using appropriate labeled training sets. Adequately\nconcatenating these modules and fine tuning the resulting system can be viewed\nas an algebraic operation in a space of models. The resulting model answers a\nnew question, that is, converting the image of a text page into a computer\nreadable text.\n  This observation suggests a conceptual continuity between algebraically rich\ninference systems, such as logical or probabilistic inference, and simple\nmanipulations, such as the mere concatenation of trainable learning systems.\nTherefore, instead of trying to bridge the gap between machine learning systems\nand sophisticated \"all-purpose\" inference mechanisms, we can instead\nalgebraically enrich the set of manipulations applicable to training systems,\nand build reasoning capabilities from the ground up.",
            "comment": "15 pages - fix broken pagination in v2",
            "journal_ref": "",
            "doi": "",
            "primary_category": "cs.AI",
            "categories": [
                "cs.AI",
                "cs.LG"
            ],
            "links": [
                "http://arxiv.org/abs/1102.1808v3",
                "http://arxiv.org/pdf/1102.1808v3"
            ],
            "pdf_url": "http://arxiv.org/pdf/1102.1808v3"
        },
        {
            "entry_id": "http://arxiv.org/abs/1610.08251v1",
            "updated": "2016-10-26 09:35:11+00:00",
            "published": "2016-10-26 09:35:11+00:00",
            "title": "Quantum-enhanced machine learning",
            "authors": [
                "Vedran Dunjko",
                "Jacob M. Taylor",
                "Hans J. Briegel"
            ],
            "summary": "The emerging field of quantum machine learning has the potential to\nsubstantially aid in the problems and scope of artificial intelligence. This is\nonly enhanced by recent successes in the field of classical machine learning.\nIn this work we propose an approach for the systematic treatment of machine\nlearning, from the perspective of quantum information. Our approach is general\nand covers all three main branches of machine learning: supervised,\nunsupervised and reinforcement learning. While quantum improvements in\nsupervised and unsupervised learning have been reported, reinforcement learning\nhas received much less attention. Within our approach, we tackle the problem of\nquantum enhancements in reinforcement learning as well, and propose a\nsystematic scheme for providing improvements. As an example, we show that\nquadratic improvements in learning efficiency, and exponential improvements in\nperformance over limited time periods, can be obtained for a broad class of\nlearning problems.",
            "comment": "5+15 pages. This paper builds upon and mostly supersedes\n  arXiv:1507.08482. In addition to results provided in this previous work, here\n  we achieve learning improvements in more general environments, and provide\n  connections to other work in quantum machine learning. Explicit constructions\n  of oracularized environments given in arXiv:1507.08482 are omitted in this\n  version",
            "journal_ref": "Phys. Rev. Lett. 117, 130501 (2016)",
            "doi": "10.1103/PhysRevLett.117.130501",
            "primary_category": "quant-ph",
            "categories": [
                "quant-ph",
                "cs.AI",
                "cs.LG"
            ],
            "links": [
                "http://dx.doi.org/10.1103/PhysRevLett.117.130501",
                "http://arxiv.org/abs/1610.08251v1",
                "http://arxiv.org/pdf/1610.08251v1"
            ],
            "pdf_url": "http://arxiv.org/pdf/1610.08251v1"
        },
        {
            "entry_id": "http://arxiv.org/abs/1811.03392v1",
            "updated": "2018-11-08 13:09:05+00:00",
            "published": "2018-11-08 13:09:05+00:00",
            "title": "Transformative Machine Learning",
            "authors": [
                "Ivan Olier",
                "Oghenejokpeme I. Orhobor",
                "Joaquin Vanschoren",
                "Ross D. King"
            ],
            "summary": "The key to success in machine learning (ML) is the use of effective data\nrepresentations. Traditionally, data representations were hand-crafted.\nRecently it has been demonstrated that, given sufficient data, deep neural\nnetworks can learn effective implicit representations from simple input\nrepresentations. However, for most scientific problems, the use of deep\nlearning is not appropriate as the amount of available data is limited, and/or\nthe output models must be explainable. Nevertheless, many scientific problems\ndo have significant amounts of data available on related tasks, which makes\nthem amenable to multi-task learning, i.e. learning many related problems\nsimultaneously. Here we propose a novel and general representation learning\napproach for multi-task learning that works successfully with small amounts of\ndata. The fundamental new idea is to transform an input intrinsic data\nrepresentation (i.e., handcrafted features), to an extrinsic representation\nbased on what a pre-trained set of models predict about the examples. This\ntransformation has the dual advantages of producing significantly more accurate\npredictions, and providing explainable models. To demonstrate the utility of\nthis transformative learning approach, we have applied it to three real-world\nscientific problems: drug-design (quantitative structure activity relationship\nlearning), predicting human gene expression (across different tissue types and\ndrug treatments), and meta-learning for machine learning (predicting which\nmachine learning methods work best for a given problem). In all three problems,\ntransformative machine learning significantly outperforms the best intrinsic\nrepresentation.",
            "comment": "",
            "journal_ref": "",
            "doi": "",
            "primary_category": "cs.LG",
            "categories": [
                "cs.LG",
                "stat.ML"
            ],
            "links": [
                "http://arxiv.org/abs/1811.03392v1",
                "http://arxiv.org/pdf/1811.03392v1"
            ],
            "pdf_url": "http://arxiv.org/pdf/1811.03392v1"
        }
    ]
}