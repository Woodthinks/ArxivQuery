{
    "results": [
        {
            "entry_id": "http://arxiv.org/abs/2310.04585v3",
            "updated": "2024-07-11 20:01:41+00:00",
            "published": "2023-10-06 20:57:34+00:00",
            "title": "Interventions Against Machine-Assisted Statistical Discrimination",
            "authors": [
                "John Y. Zhu"
            ],
            "summary": "I study statistical discrimination driven by verifiable beliefs, such as\nthose generated by machine learning, rather than by humans. When beliefs are\nverifiable, interventions against statistical discrimination can move beyond\nsimple, belief-free designs like affirmative action, to more sophisticated\nones, that constrain decision makers based on what they are thinking. Such mind\nreading interventions can perform well where affirmative action does not, even\nwhen the minds being read are biased. My theory of belief-contingent\nintervention design sheds light on influential methods of regulating machine\nlearning, and yields novel interventions robust to covariate shift and\nincorrect, biased beliefs.",
            "comment": "",
            "journal_ref": "",
            "doi": "",
            "primary_category": "econ.TH",
            "categories": [
                "econ.TH",
                "cs.LG"
            ],
            "links": [
                "http://arxiv.org/abs/2310.04585v3",
                "http://arxiv.org/pdf/2310.04585v3"
            ],
            "pdf_url": "http://arxiv.org/pdf/2310.04585v3"
        },
        {
            "entry_id": "http://arxiv.org/abs/2008.13145v1",
            "updated": "2020-08-30 11:44:37+00:00",
            "published": "2020-08-30 11:44:37+00:00",
            "title": "Performance portability through machine learning guided kernel selection in SYCL libraries",
            "authors": [
                "John Lawson"
            ],
            "summary": "Automatically tuning parallel compute kernels allows libraries and frameworks\nto achieve performance on a wide range of hardware, however these techniques\nare typically focused on finding optimal kernel parameters for particular input\nsizes and parameters. General purpose compute libraries must be able to cater\nto all inputs and parameters provided by a user, and so these techniques are of\nlimited use. Additionally, parallel programming frameworks such as SYCL require\nthat the kernels be deployed in a binary format embedded within the library. As\nsuch it is impractical to deploy a large number of possible kernel\nconfigurations without inflating the library size.\n  Machine learning methods can be used to mitigate against both of these\nproblems and provide performance for general purpose routines with a limited\nnumber of kernel configurations. We show that unsupervised clustering methods\ncan be used to select a subset of the possible kernels that should be deployed\nand that simple classification methods can be trained to select from these\nkernels at runtime to give good performance. As these techniques are fully\nautomated, relying only on benchmark data, the tuning process for new hardware\nor problems does not require any developer effort or expertise.",
            "comment": "13 pages, 7 figures, 2 tables",
            "journal_ref": "",
            "doi": "",
            "primary_category": "cs.PF",
            "categories": [
                "cs.PF",
                "cs.DC",
                "cs.LG"
            ],
            "links": [
                "http://arxiv.org/abs/2008.13145v1",
                "http://arxiv.org/pdf/2008.13145v1"
            ],
            "pdf_url": "http://arxiv.org/pdf/2008.13145v1"
        },
        {
            "entry_id": "http://arxiv.org/abs/2311.09565v2",
            "updated": "2023-12-13 14:19:59+00:00",
            "published": "2023-11-16 05:01:15+00:00",
            "title": "The Physical Logic of Protein Machines",
            "authors": [
                "John M. McBride",
                "Tsvi Tlusty"
            ],
            "summary": "Proteins are intricate molecular machines whose complexity arises from the\nheterogeneity of the amino acid building blocks and their dynamic network of\nmany-body interactions. These nanomachines gain function when put in the\ncontext of a whole organism through interaction with other inhabitants of the\nbiological realm. And this functionality shapes their evolutionary histories\nthrough intertwined paths of selection and adaptation. Recent advances in\nmachine learning have solved the decades-old problem of how protein sequence\ndetermines their structure. However, the ultimate question regarding the basic\nlogic of protein machines remains open: How does the collective physics of\nproteins lead to their functionality? and how does a sequence encode the full\nrange of dynamics and chemical interactions that facilitate function? Here, we\nexplore these questions within a physical approach that treats proteins as\nmechano-chemical machines, which are adapted to function via concerted\nevolution of structure, motion, and chemical interactions.",
            "comment": "",
            "journal_ref": "",
            "doi": "",
            "primary_category": "q-bio.BM",
            "categories": [
                "q-bio.BM",
                "physics.bio-ph",
                "q-bio.PE"
            ],
            "links": [
                "http://arxiv.org/abs/2311.09565v2",
                "http://arxiv.org/pdf/2311.09565v2"
            ],
            "pdf_url": "http://arxiv.org/pdf/2311.09565v2"
        },
        {
            "entry_id": "http://arxiv.org/abs/2010.04894v2",
            "updated": "2021-11-29 01:59:11+00:00",
            "published": "2020-10-10 03:46:59+00:00",
            "title": "HAMLET: A Hierarchical Agent-based Machine Learning Platform",
            "authors": [
                "Ahmad Esmaeili",
                "John C. Gallagher",
                "John A. Springer",
                "Eric T. Matson"
            ],
            "summary": "Hierarchical Multi-Agent Systems provide convenient and relevant ways to\nanalyze, model, and simulate complex systems composed of a large number of\nentities that interact at different levels of abstraction. In this paper, we\nintroduce HAMLET (Hierarchical Agent-based Machine LEarning plaTform), a hybrid\nmachine learning platform based on hierarchical multi-agent systems, to\nfacilitate the research and democratization of geographically and/or locally\ndistributed machine learning entities. The proposed system models a machine\nlearning solutions as a hypergraph and autonomously sets up a multi-level\nstructure of heterogeneous agents based on their innate capabilities and\nlearned skills. HAMLET aids the design and management of machine learning\nsystems and provides analytical capabilities for research communities to assess\nthe existing and/or new algorithms/datasets through flexible and customizable\nqueries. The proposed hybrid machine learning platform does not assume\nrestrictions on the type of learning algorithms/datasets and is theoretically\nproven to be sound and complete with polynomial computational requirements.\nAdditionally, it is examined empirically on 120 training and four generalized\nbatch testing tasks performed on 24 machine learning algorithms and 9 standard\ndatasets. The provided experimental results not only establish confidence in\nthe platform's consistency and correctness but also demonstrate its testing and\nanalytical capacity.",
            "comment": "",
            "journal_ref": "",
            "doi": "10.1145/3530191",
            "primary_category": "cs.LG",
            "categories": [
                "cs.LG",
                "cs.AI",
                "cs.MA"
            ],
            "links": [
                "http://dx.doi.org/10.1145/3530191",
                "http://arxiv.org/abs/2010.04894v2",
                "http://arxiv.org/pdf/2010.04894v2"
            ],
            "pdf_url": "http://arxiv.org/pdf/2010.04894v2"
        },
        {
            "entry_id": "http://arxiv.org/abs/2101.00346v1",
            "updated": "2021-01-02 01:01:20+00:00",
            "published": "2021-01-02 01:01:20+00:00",
            "title": "Minimum Viable Model Estimates for Machine Learning Projects",
            "authors": [
                "John Hawkins"
            ],
            "summary": "Prioritization of machine learning projects requires estimates of both the\npotential ROI of the business case and the technical difficulty of building a\nmodel with the required characteristics. In this work we present a technique\nfor estimating the minimum required performance characteristics of a predictive\nmodel given a set of information about how it will be used. This technique will\nresult in robust, objective comparisons between potential projects. The\nresulting estimates will allow data scientists and managers to evaluate whether\na proposed machine learning project is likely to succeed before any modelling\nneeds to be done.\n  The technique has been implemented into the open source application MinViME\n(Minimum Viable Model Estimator) which can be installed via the PyPI python\npackage management system, or downloaded directly from the GitHub repository.\nAvailable at https://github.com/john-hawkins/MinViME",
            "comment": "11 pages, 4 figures",
            "journal_ref": "Proceedings of the 6th International Conference on Computer\n  Science, Engineering And Applications (CSEA 2020), December 18 ~ 19, pp.\n  37-46, Volume 10, Number 18",
            "doi": "10.5121/csit.2020.101803",
            "primary_category": "cs.LG",
            "categories": [
                "cs.LG",
                "cs.SE",
                "68T01",
                "I.2.6; I.5.2"
            ],
            "links": [
                "http://dx.doi.org/10.5121/csit.2020.101803",
                "http://arxiv.org/abs/2101.00346v1",
                "http://arxiv.org/pdf/2101.00346v1"
            ],
            "pdf_url": "http://arxiv.org/pdf/2101.00346v1"
        }
    ]
}